---
title: CSV Row Chunking
---

CSV row chunking is a method of splitting CSV files based on the number of rows, rather than character count. This approach treats each row (or group of rows) as a semantic unit, preserving the integrity of individual records while enabling efficient processing of tabular data.

## Code

```python   
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.row import RowChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.csv_reader import CSVReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = Knowledge(
    vector_db=PgVector(table_name="imdb_movies_row_chunking", db_url=db_url),
)

asyncio.run(knowledge_base.add_content_async(
    url="https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
    reader=CSVReader(
        chunking_strategy=RowChunking(),
    ),
))  

# Initialize the Agent with the knowledge_base
agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)

# Use the agent 
agent.print_response("Tell me about the movie Guardians of the Galaxy", markdown=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector agno
    ```
  </Step>


    <Snippet file="run-pgvector-step.mdx" />


  <Step title="Run Agent">
    <CodeGroup>
    ```bash Mac
    python cookbook/knowledge/chunking/csv_row_chunking.py
    ```

    ```bash Windows
    python cookbook/knowledge/chunking/csv_row_chunking.py 
    ```
    </CodeGroup>
  </Step>
</Steps>

## CSV Row Chunking Params

<Snippet file="chunking-csv-row.mdx" /> 
